---
output: html_document
---
  ---
  "Profiling Household Energy Consumption"
  Alan Colver, Matthew Herpich
  95-791 Final Project
  May 8, 2016
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract
Understanding the nation's energy usage patterns is critical to building a sustainable infrastructure and reducing/mitigating total energy consumption. Identifying areas of waste and opportunities to implement resource-saving practices could drastically reduce the cost of various energy types. Significant time, money, and effort has been invested in the "smart grid", a blending of the nation's existing energy infrastructure with modern technologies and adaptive learning algorithms.  Prime examples of this include Nest and Google's Power Meter, both of which attempt to learn from and predict energy usage patterns with the goal of helping reduce excess power consumption.  This problem is highly complex, with multiple sources of power per household and numerous potential predictors of consumption, including both demographic features and household attributes.

In our data mining analysis, we reviewed the profiles of approximately 4,500 households based on publicly-available energy consumption data collected by the Energy Information Administration ("EIA") to identify patterns related to the usage of electricity and natural gas. From this data, we: (1) identified the most significant predictors of energy consumption based on the data; (2) trained models to help predict total energy consumption and the impact certain features have on overall consumption; and (3) utilized this data to recommend features on which homeowners and landlords can focus to reduce their overall energy consumption profiles. 

## Introduction
Energy consumption in U.S. households consists primarily of electric power and natural gas usage but also may include LPG, fuel oil, kerosene, and other products. The purpose of this project was to integrate energy consumption data based on the Residential Energy Consumption Survey from 2005 with certain demographic and household information also provided by the survey. The dataset of interest had 3 main components: (1) energy consumption data, including power, natural gas, LPG, and kerosene, both in native units and in BTU, found in the energy_consumption.csv file; (2) household measurements, including total square footage, square footage by room, square footage of heated versus unheated portions, and square footage of cooled versus uncooled portions, in the house.csv file; and (3) demographic information of the owner(s) of the household, including number of members, age of members, employment status, work status, and income bracket, found in the household.csv file. These files were all linked together by a shared ID field (DOEID).

In total, this dataset was fairly rich. The energy consumption data had total energy consumption by product but also estimated consumption for each product by end use. For power consumption, the data was subdivided into dryer use, dishwater use, freezer use, and other uses, while for natural gas consumption, the data included both appliance and heating uses. Though a significant number of output variables was present, most of the data collected was for electric power and natural gas usage. Given these tend to be the predominant sources of household energy, we focused primarily on these two metrics (and their aggregate sum). The house.csv file consisted of 30 potential attributes primarily revolving around square footage metrics in total and by household room. The household.csv file contained 28 attributes related to demographic data associated with each household. Thus, in total, there were over 15 viable outputs for a predictive model and nearly 60 potential predictors from which to choose.

To analyze this data, we relied on standard statistical programming packages found in the R library plus supplementary tools including Excel and Tableau. This report is merely meant to serve as an introduction to the project and our initial results. The methodologies utilized here can be further refined and expanded to create a more tailored and customized solution.

## Method and Result
### Data Preparation
As mentioned above, the source data for the project was publicly available and based on the Residential Energy Consumption Survey from 2005 as sourced from the EIA. The three Excel files were linked via a DOEID which served as the Foreign Key, and all attribute variables were identified in a Code Book produced by the EIA. In total, there were 4382 unique measurements across 89 attributes (excluding DOEID).

The first part of the project revolved around importing the data into an R database and sanitizing the data. Many measurements in the set were "NA" or set to a default parameter (e.g., 9999) which meant no data or information skipped. Before any thorough analysis was run, we outlined steps needed to cleanse this data to make it suitable for analysis, as discussed in the following sections.

#### Removing Columns
We quickly realized that not all attributes had meaningful amounts of data with which to run predictive algorithms. While processes such as sampling or predictive modeling can help eliminate NULL or unknown values, if an attribute contains mostly unknown data, we believe these techniques may create a sense of false precision in a trained model's predictive capabilities. As a result, we implemented code to remove features in the data set if greater than 50% of the feature's values were either missing/default or "NA". In particular, we noticed that many of the output variables revolving around energy consumption from fuels other than electric power or natural gas contained insufficient measurements per our algorithm. This makes sense - most households don't use significant quantities of kerosene, LPG, or other fuel sources (these are more for industrial purposes). As a result, we limited our approach to predicting power usage, natural gas usage, and total usage as defined by power plus natural gas usage. 

#### Accounting for Missing Data
For the features which remained after the initial level of pruning, we implemented two methodologies to remove the NULL/default or "NA" values. For almost all features, we replaced each instance of a NULL/default or "NA" with a sampled value from the non-NULL elements of that feature. This approach maintains the shape of the feature distributions while simultaneously avoids discarding observations which could be of importance. When dealing with total BTU consumption, almost all of the observations had numeric values for power usage; however, many of the natural gas usage values were NULL. To create a more accurate output set, we implemented a linear regression model for natural gas BTU usage by using the remaining non-consumption features and replaced the NULL/default values with the regressed output.

#### Creation of New Features
We found the feature set to be very fulsome and thus saw a limited need to create new features. However, we did add a total BTU usage output based on the sumtotal of the electric power BTU usage and the natural gas usage. This output variable would be a more holistic representation of a typical household's energy consumption profile, particularly in the Northern U.S. where natural gas consumption is high. We also noted that there were features for the age of each member of a household and for the total number of household members but not one for the average age of a household member. Given the hypothesis that the elderly tend to use less energy than younger families, we thought it could be significant in forming a predictive analysis.

### Feature Selection
How much energy a household uses is a complex matter: it is potentially determined by many variables. Additionally, as mentioned previously, the dataset from the EIA has a rich set of features from which to run predictive algorithms. For the first part of the project, we wanted to identify which aspects of the homes and the homeowners contribute the most to their energy use. By focusing our efforts on the most impactful factors, we could then identify which changes would potentially yield the best results for clients who wish to better predict or reduce their overall energy consumption.

#### Recursive Feature Elimination
In attempt to understand the impact of the most important variables on a household's energy consumption profile, we ran Recursive Feature Elimination ("RFE"), which is a method of building many models with all the variables and removing those variables that have little reduction to the total error. Running this method on our input data, we can see that there are several key features that explain much of the variance and that a majority of the features contribute little to the overall variability of the data.  This is as we would expect for a highly dimensional feature set with a number of potentially correlative features. We used 10-fold cross validation, a method of running multiple instances of model training to help prune the selection process based on estimates of error rates, on RFE to avoid over-fitting our results.  Over-fitting involves training highly complex models on data which are too sensitive to naturally-occurring variability in the dataset and thus generate additional error when predicting output behavior.

![RFE](feature_count_vs_error.png)

And now, if we zoom in, we can see our most useful predictive features for the household energy consumption profile:

![Top Features](impactful_variables.png)

| Variable | Description                                       | Root Mean Squared Error |
| -------- | ------------------------------------------------- | ----------------------: |
| NHSLDMEM | Number that live in the household                 | 0.1035                  |
| TYPEHUQ  | Type of home (e.g. single-family, apartment, etc) | 0.2412                  |
| HD65     | Number of heat-degree days (65 base temp)         | 0.3515                  |
| TOTHSQFT | Total home square feet                            | 0.3958                  |
| TOTSQFT  | Total square feet                                 | 0.4165                  |
| LRGSTATE | Is a large state (i.e. CA, FL, NY, TX)            | 0.4151                  |

Our results show that the number of household members contributed the most to reducing the error in our model. This is likely due to the more frequent usage of and greater number of appliances by household members. The other findings are also pretty self-evident. The type of home is correlated to total square footage. Square footage is obviously related to how much heating/cooling is required for a household. The number of heat degree days clearly would be related to total heat usage during cooler periods. 

The large states, however, have more to do with geography and less to do with population. The graph below shows KWH usage by state. And, as can be expected, the lower/warmer states use more electricity for cooling their homes in the summer months.

![KWH by state](KWH_Use_by_State.png)


#### Principal Component Analysis
Another way to understand the impact our variables have on energy usage involves examining how the variables interact with one another and with the data as a whole. We accomplish this task through the use of Principal Component Analysis ("PCA"). With PCA, we transform the variables along the Principal Components of the data, or the orientations of maximum dispersion (allowing for easier delineations among feature sets). These components represent a weighted combination of the underlying features as projections along these orientations and capture the interplay amongst these variables through retained variance of the underlying dataset. They are arranged by how much each component contributes to the variance, with the first Principal Component contributing the most to the overall retained variance.

We can see in the graph below that our most explanatory component (PC1) is square footage, and its opposite is the type of home (TYPEHUQ), with higher category number typically denoting smaller home types (e.g., apartments). This finding is intuitive. Larger homes take more energy to regulate temperature, and smaller homes require less.

![Top 2 component interactions](biplot_pca1_pca2.png)

Principal Component 2 (PC2), however, reveals an interesting finding. It appears that older persons tend to use less energy, supporting our initial hypothesis. We can see that the older the primary owner is (AGEHHMEM1) and whether or not they are in retirement (RETIREPY) is associated with lower energy consumption. Conversely, we see that those who are working (WORKPAY) and have more people at home (NHSLDMEM) (e.g., young families) use more energy. One hypothesis is that older persons are more experienced with home ownership. They have more years of home ownership and have thus optimized the heating/cooling of their homes to reduce costs. An alternative hypothesis is that older people tend to use common appliances with less frequency than younger individuals, couples or families. The elderly often cook and do laundry less and typically don't have significant number of energy-consuming appliances running simultaneously. Also, it is likely that the elderly are more cost conscious and careful to not be wasteful with energy usage by leaving appliances running when out or not in use. Larger families or households with kids likely tend to be less conservative when monitoring energy use given the large number of appliances and constant needs for running dishwashers and laundry.

### Classification Algorithms
Given that this feature set and output set lend themselves more to regression-type modeling with numeric outputs than classification outputs, the applicability of classification models on this data set was mitigated. However, we did utilize classification models, namely the support vector machine ("SVM") and classification tree, to train models to help validate the importance of features presented during the Principal Component Analysis on predicting low or high energy consumption per household.

To begin, we subdivided the output dataset (total energy usage) into three categories: (1) "Low" - energy usage below 1 standard deviation from the mean; (2) "High" - above 1 standard deviation from the mean; and (3) "Normal" - within one standard deviation from the mean. We then trained the SVM and classification tree models on the PCA data set utilizing cross validation to predict accuracy rates. We realized that these models contained very high accuracy rates but low rates of identification for "Low" or "High" values given the number of "Normal" values was too broad. Thus, we tuned the standard deviation parameter to 0.5 * standard deviation and re-ran our analysis. The important element of the feature selection component of this project was to be able to accurately pinpoint those features which differentiated low or high household energy consumption.  Thus, we emphasized the importance of "anomaly" detection in household energy consumption over total model accuracy. As shown below, this led to a relatively even set of classifications.

![Histogram of BTU Usage Categorization](HistCons.png)

After feeding this output with the top 24 PCA components (representing 90% of the underlying variance of the dataset) to the classification algorithms, we were able to achieve a meaningful improvement over the default predictor set (mode value predictor) with respect to accuracy while simultaneously identifying over 50% of the "Low" and "High" cases. The SVM model performed the best, averaging 62% accuracy over the cross-validation folds utilizing the PCA data.


| Model    | Accuracy Rate   | Identification Rate, High   | Identification Rate, Low    |
| -------- | --------------- | --------------------------- | --------------------------- |
| SVM      | 61.9%           | 56.0%                       | 54.8%                       |
| Tree     | 53.6%           | 58.6%                       | 48.7%                       |
| Default  | 42.9%           | 0.0%                        | 0.0%                        |


While the classification models did not help quantify the impact individual features had on household energy consumption (done using predictive algorithms as described below), the models did validate that the PCA feature selection findings did significantly outperform the default value selection when categorizing household energy consumption as "Low", "High", or "Normal". Thus, we can conclude that there is a significant determining factor with respect to the features emphasized in the set of Principal Components which does contribute to anomalous energy usage based on the average household profile as represented in the data set.

###Predictive Algorithms
Finding predictive relationships between household measurements and demographic information and the energy consumption profile of a household will ultimately help homeowners and tenants estimate projected energy usage and help homeowners and business owners reduce their carbon footprints. There are the more apparent predictive relationships, such as the relationship between total BTU usage and total household square footage or total BTU usage and number of heat-degree days (shown below). There are also less obvious predictive relationships, such as the average age of a household member, the type of housing unit or wall, and the work status of the household owner. Additionally, the dataset contained variables which were both continuous value and which were classifiers (for example, type of home had 5 possible responses, 1:5, with each response representing a broad categorization of a type of housing). Depending on how the classifier variables were ordered, a line or a quadratic function may make sense to predict across classifier values (see below for examples).

| Feature                | Correlation To BTU |
| ---------------------- | ------------------ |
| Total Square Feet      |  0.48              |
| Heat Deg-Days (65)     |  0.36              |
| House Type             | -0.36              |
| House Members          |  0.30              |

```{r,echo=FALSE}
library(ggplot2)
import.csv <- function(filename){
  return(read.csv(filename,sep="," ,header=TRUE))
}
my.data <- import.csv("cleaned_data_FINAL.csv")
h1 <- ggplot(my.data, aes(x=TOTSQFT,y=TOTBTU)) + geom_point(color="blue")+ggtitle("BTU Usage Vs Household Square Feet")+theme(plot.title = element_text(face="bold")) + xlab("Square Feet") + ylab("BTU") + geom_smooth(method=lm)
print(h1)

h2 <- ggplot(my.data, aes(x=HD65,y=TOTBTU)) + geom_point(color="blue")+ggtitle("BTU Usage Vs Heat Deg-Days (Base 65)")+theme(plot.title = element_text(face="bold")) + xlab("HD65") + ylab("BTU") + geom_smooth(method=lm)
print(h2)

h3 <- ggplot(my.data, aes(x=TYPEHUQ,y=TOTBTU)) + geom_point(color="blue")+ggtitle("BTU Usage Vs Type of House")+theme(plot.title = element_text(face="bold")) + xlab("House Type") + ylab("BTU") + geom_smooth(method=lm)
print(h3)

h4 <- ggplot(my.data, aes(x=NHSLDMEM,y=TOTBTU)) + geom_point(color="blue")+ggtitle("BTU Usage Vs Number Household Members")+theme(plot.title = element_text(face="bold")) + xlab("Members") + ylab("BTU") + geom_smooth(method=lm)
print(h4)

```

For the predictive part of this project, we focused on three main energy consumption output variables: (1) total electric power usage; (2) total natural gas usage (more prevalent in the Northern U.S.; commonly used for heating and cooking); and (3) total BTU usage of power and natural gas combined. As the predictive model would need to take many input features and output an estimated energy usage, we focused our predictive analysis on multivariate regression models. After exploring numerous types of linear and non-linear regression models and running such models through cross validation techniques, we settled on training three types of models for our final analysis: (1) the standard linear model; (2) the standard linear model with quadratic features for continuous variables; and (3) the decesion tree regression model. We then performed one final cross validation on these three models and included the default predictor for comparitive purposes (generates the mean output for all inputs). The root mean squared error ("RMSE") results shown below are for total BTU consumption using a five-fold cross validation of the data set with training/validation splits of 80%/20%. 

| Model Type             | RMSE (Total BTU)   |
| ---------------------- | ------------------ |
| Quadratic Regression   | 37,598.02          |
| Linear Regression      | 37,715.17          |
| Regression Tree        | 41,841.85          |
| Default                | 51,258.91          |

As shown above, the linear regression model with the ability to tune quadratic parameters (up to third order) for the most significant continuous feature variables performed the best on the test data, slightly edging the standard linear model.  The tuned decision tree regression model also meaningfully outperformed the default data set but failed to match the result of the linear and quadratic models.

The quadratic regression model reduced RMSE by 25% for all three output types (BTU, power, natural gas) as shown below.

| Output            | Fit RMSE (BTU)  | Default RMSE (BTU)  | Error Reduction (%)  |
| ----------------- | --------------- | ------------------- | -------------------- |
| Total BTU         | 37,598          | 51,259              | 26.7%                |
| Electric Power    | 19,546          | 25,612              | 23.7%                |
| Natural Gas       | 31,433          | 42,495              | 26.0%                |

But is this result statistically significant? We first ran a paired t-test on the vector of squared errors from both the quadratic predictor and the default predictor for BTU. As we expected, the result was to reject the NULL hypothesis and conclude the predictor model reduces the squared error. We then ran a paired t-test on the vector of squared errors from the quadratic predictor and the tree regression. Again, the result was to reject the NULL hypothesis. Finally, we ran the paired t-test on the quadratic versus linear model. Here we obtained a p-value of 7%. Thus, for an alpha of 5%, we cannot reject the NULL hypothesis. In summary, we concluded that both the linear and quadratic models beat the default and tree predictors but that the quadratic may not statistically outperform the linear model with 95% degree of confidence.

| Model Type 1           | Model Type 2          | T-Value    | P-Value    |
| ---------------------- | --------------------- | ---------- | ---------- |
| Quadratic Regression   | Default               | -10.56     | < 0.2e-15  |
| Quadratic Regression   | Regression Tree       | -4.55      | 0.6e-5     |
| Quadratic Regression   | Linear Regression     | -1.80      | 0.07       | 

Finalizing our regression models allowed us to measure the corresponding change of energy consumption by predictor variable.  This ability represents a powerful tool when analyzing features which can potentially reduce a household's carbon footprint. Sample coefficients for the non-quadratic terms of the regression model are pasted below. As an example, the coefficient for the NHSLDMEM (number of household members) variable is 7961. Thus, we know that for each person increase in the number of household members, a household should expect its total BTU consumption to increase by nearly 8,000 BTU holding all other predictors constant.  This trend can be made for each of the predictive features in the set.

|(Intercept)     |   TYPEHUQ        |  CD65     |  WALLTYPE     |   ...  |  NHSLDMEM     |  ... 
-----------------|------------------|-----------|---------------|--------|---------------|------
|13036574.517305 |   -6340.832303   |  7.175452 |  -1316.502376 |   ...  |   7960.587455 |  ...

####Predicting Energy Consumption By Use
Another informative component of this data set is that it includes estimated breakdowns of total power and natural gas usage by category. For power consumption, for example, each record in the data set can be broken apart into dryer use, dishwasher use, freezer use, refrigerator use, AC use, water heater use, space heater use, and other appliance use (we had to manipulate this feature so as not to double count the kitchen appliances). For natural gas consumption, each record in the data set can be broken apart into appliance use, water heater use, and space heater use. This creates another layer to the predictive capabilities of a model in that the consumption profile by end use can potentially be mapped onto the feature set. Thus, we can see more granular details around estimated energy consumption, like total power consumption by AC/heater by type of or age of building or total appliance consumption based on number of household members.

The plots below show the average breakdown of energy consumption for both power and natural gas based on the data set. As clearly illustrated, general electric appliance use on average accounts for nearly 50% of all power consumption by household, with AC and refrigerator being the next significant power sinks. On the natural gas side, the vast majority of natural gas is used for heating purposes, both for household heating and for water heaters.

```{r,echo=FALSE}
x1<-c("Dryer","Dishwasher","Freezer","Refigerator","AC","Water Heater","Space Heater","Other Appliance")
y1<-c(0.06,0.01,0.04,0.14,0.16,0.08,0.06,0.44)
x2<-c("Appliance","Water Heater","Space Heater")
y2<-c(0.18,0.38,0.44)
data1<-data.frame(x=x1,y=y1)
data2<-data.frame(x=x2,y=y2)
h1 <- ggplot(data1, aes(x=x1,y=y1)) + geom_bar(fill="blue",stat="identity")+ggtitle("Average Power Consumption By Type")+theme(plot.title = element_text(face="bold"))+labs(x="Type",y="Percent of Total")
h2 <- ggplot(data2, aes(x=x2,y=y2)) + geom_bar(fill="blue",stat="identity")+ggtitle("Average Gas Consumption By Type")+theme(plot.title = element_text(face="bold"))+labs(x="Type",y="Percent of Total")
print(h1)
print(h2)

```

By training the same types of regression models on the full feature set by estimated output, we can then enhance our overall predictive capabilities to have more detail than just household consumption. For example, if we regress total other appliance usage (BTUELAPL - (BTUELCDR + BTUELDWH + BTUELFZZ)) against the full feature set and look at the number of household members (NHSLDMEM), we can expect a 1,960 BTU increase in power consumption for appliance for each additional member holding all other variables constant. Another example would be if we regressed total AC usage (BTUELCOL) with the full feature set and look at the coefficient of CD65, or the number of cooling days set to 65 degree normalized temperature. Given the coefficient is 4.9, we can glean that for each cooling day to 65 degrees, we can expect an incremental 5 BTU increase in our household AC power usage. These values represent merely a subset of the potentially interesting feature-output predictive relationships we now can estimate using our regression models.

One interesting higher order trend of which to be mindful is total BTU usage by household splitting electric power and natural gas. Across the dataset, on average, household BTU consumption tended to run 40% electric power, 60% natural gas. We know that gas is mostly used for heating purposes, particularly in the Northern U.S. Thus, we should see a clear linear trend between BTUNG (total natural gas usage) and HD65 (heating days to 65 degrees). Indeed, as evidenced by the plot below, there is an apparent linear trend between the variables (r=0.53).

```{r,echo=FALSE}
h1 <- ggplot(my.data, aes(x=HD65,y=BTUNG)) + geom_point(color="blue")+ggtitle("Natural Gas Usage Vs Heat-Deg Days (Base 65)")+theme(plot.title = element_text(face="bold")) + xlab("HD65") + ylab("NG_BTU") + geom_smooth(method=lm)
print(h1)
```


## Conclusion and Further Work
Our conclusions for this project revolve around the original stated goals and can be summarized as: (1) the ability to predict highly correlative features for household energy consumption is most certainly possible and achievable to a certain degree based on the publicly available data sourced from the EIA and (2) basic predictive modeling can estimate household energy consumption significantly better than merely taking averages across the feature set. Though we had only 4,382 data points, hardly a comprehensive data set when predicting for the average U.S. household, certain features definitely stood out as significant - total square footage, number of household memebers, type of household, number of heat-degree days, and how frequently the householder reporting being at home. While these are somewhat intuitive, utilizing predictive regression modeling and feature selection algorithms helped to quantify the relative importance of these features to overall energy consumption and further elucidate relationships among more complex potential features (e.g., average age of household members, average age of house, wall type, employment status, and income type). We feel confident that our first attempt at training predictive models can aid significantly in forming theses around the importance of various predictors on energy consumption, and given a more fulsome data set and higher-order regression modeling algorithms, we believe we can further tune these models to reduce the RMSE even more.

Having a predictive algorithm which accurately helps quantify household energy consumption and guides users on energy consumption reduction tips is already available (to varying degrees of quality) among tech-friendly energy appliances (e.g., the Nest home thermostat). Continuing to improve these algorithms utilizing ever-expanding data sets which can be tuned to the specific end user is highy important to maintaining a carbon-reduction initiative in the U.S. and mitigating stress on the existing grid. We would welcome the opportunity to utilize even more granular data with more measurements and additional dimensionality to improve upon our algorithms.  For example, rather than taking basket averages across the U.S. with the only major geographic parameter being the division among the four largest states and "other", we think a logical next step would be to collect sufficient measurements by region or state so as to better understand regional variances in household energy consumption.

## Takeaways
This project did a great job of demonstrating the reality of practicing data mining techniques on real world datasets compared to the pre-processed examples that students are accustomed to working with. Real data sets are messy. Real data sets don't always have that one obvious correlation or conclusion. There is a lot of noise and a lot of missing data. Given this new perspective, we now fully appreciate the significance of allocating the appropriate amount of time to understanding the variables and dealing with missing values. We also grew to appreciate the importance of interacting with the client early on so as to tailor the data mining algorithms and procedures to meet the client's particular needs. After having a brief discussion with the client to clarify expectations in Week 2 of the project, we formalized a well-defined plan of action for completing our assessment. Doing this earlier in the process would have saved man hours spent testing various approaches which ultimately did not prove fruitful.
